# å¯¼å…¥æ‰€éœ€çš„åº“
import torch
import streamlit as st
st.set_page_config(page_title="Yuan2.0 å­¦æœ¯è®ºæ–‡åŠ©æ‰‹", page_icon="ğŸ“š", layout="wide")
from transformers import AutoTokenizer, AutoModelForCausalLM
# âœ… Prompts
from langchain_core.prompts import PromptTemplate

# âœ… Vector Stores (Chroma)
from langchain_community.vectorstores import Chroma

# âœ… Document Loaders
from langchain_community.document_loaders import PyPDFLoader

# âœ… Embeddings
from langchain_community.embeddings import HuggingFaceEmbeddings

# âœ… Chains
from langchain.chains import LLMChain  # è¿™ä¸ªç›®å‰è¿˜èƒ½ç”¨ï¼Œä½†æ¨èç”¨ Runnable æ›¿ä»£
from langchain.chains.question_answering import load_qa_chain  # ä»å¯ç”¨ï¼Œä½†é€æ­¥å¼ƒç”¨

# âœ… Custom LLM
from langchain_core.language_models import LLM
from langchain_core.callbacks import CallbackManagerForLLMRun

# âœ… Text Splitters
from langchain_text_splitters import RecursiveCharacterTextSplitter

# âœ… Schema
from langchain_core.documents import Document
import re
from collections import Counter
from typing import Any, List, Optional, Dict, TypedDict
import numpy as np

from rank_bm25 import BM25Okapi
import os
import hashlib
import json
import pickle
import io, csv
import requests
import xml.etree.ElementTree as ET
from functools import lru_cache
import time
# å‘é‡æ¨¡å‹ä¸‹è½½
from modelscope import snapshot_download
from langgraph.graph import StateGraph, END
from langgraph.graph.state import CompiledStateGraph

# å–æ¶ˆå®é™…ä¸‹è½½ï¼ˆå¦‚éœ€è¿è¡Œè¯·å–æ¶ˆæ³¨é‡Šï¼Œæ­¤å¤„ä¸ºç¤ºä¾‹ï¼‰
#model_dir = snapshot_download('AI-ModelScope/bge-small-en-v1.5', cache_dir='./')
#model_dir = snapshot_download('IEITYuan/Yuan2-2B-Mars-hf', cache_dir='./')

# å®šä¹‰æ¨¡å‹è·¯å¾„ï¼ˆè¯·æ ¹æ®å®é™…ä¸‹è½½è·¯å¾„ä¿®æ”¹ï¼‰
model_path = './IEITYuan/Yuan2-2B-Mars-hf'
embedding_model_path = './AI-ModelScope/bge-small-en-v1___5'

# å®šä¹‰æ¨¡å‹æ•°æ®ç±»å‹
torch_dtype = torch.bfloat16  # A10


# torch_dtype = torch.float16 # P100

from ui import main


if __name__ == '__main__':
    main()
                  